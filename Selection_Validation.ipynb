{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from Utilidades import *\n",
    "from Utilidades_selection_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns of the training set:  (363834, 146)\n",
      "Number of rows and columns of the test set:  (156315, 145)\n"
     ]
    }
   ],
   "source": [
    "#LECTURA DEL DATASET\n",
    "\n",
    "folder='Total'\n",
    "\n",
    "traindata=pd.read_csv(folder+'/traindata.csv')#reading the data\n",
    "testdata=pd.read_csv(folder+'/TEST.csv')#reading the data\n",
    "\n",
    "traindata=traindata.drop('ID_Customer',axis=1)\n",
    "test_ids=testdata['ID_Customer'] #Nos lo guardamos para submision\n",
    "testdata=testdata.drop('ID_Customer',axis=1)\n",
    "\n",
    "print('Number of rows and columns of the training set: ',traindata.shape)\n",
    "print('Number of rows and columns of the test set: ',testdata.shape)\n",
    "\n",
    "X_traindata=traindata.drop('Poder_Adquisitivo',axis=1)\n",
    "y_traindata=traindata['Poder_Adquisitivo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DEFINICION DE MODELOS Y SU GRID DE PARAMETROS\n",
    "\n",
    "models=[\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    RandomForestRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    xgb.XGBRegressor(),\n",
    "    lgb.LGBMRegressor()\n",
    "]\n",
    "\n",
    "\n",
    "models_table=get_models_table(models)\n",
    "\n",
    "    \n",
    "param_grid_list=[\n",
    "    #LINEAR MODELS\n",
    "    {'alpha':(0.05,100)},\n",
    "    {'alpha':(0.0001,1.0)},\n",
    "    {'l1_ratio':(0.1,1),'alpha':(0.001,1)},\n",
    "    \n",
    "    #ENSEMBLE MODELS\n",
    "    {'n_estimators': (10, 300),'min_samples_split': (2, 25),'max_features': (0.1, 0.999),'max_depth': (4,8)},\n",
    "    {'n_estimators': (10, 300),'min_samples_split': (2, 25),'max_features': (0.1, 0.999),'max_depth': (4,8)},\n",
    "    \n",
    "    {'n_estimators':(50,300),'learning_rate':(0.05,0.5),'subsample':(0.5,1),'max_depth':(4,8),\n",
    "     'min_samples_leaf':(5, 20),'min_samples_split':(2, 12)},\n",
    "    \n",
    "    {'n_estimators':(50,300),'learning_rate':(0.05,0.5),'subsample':(0.5,1),'max_depth':(4,10),'reg_alpha':(0,1.4),\n",
    "     'reg_lambda':(0,1.4),'min_child_weight':(1,10),'colsample_bytree':(0.1,1),'gamma':(0,1.4)},\n",
    "    \n",
    "    {'n_estimators':(100,3000),'learning_rate':(0.005,0.1),'subsample':(0.5,1),'max_depth':(5,15),'reg_alpha':(0,1.4),\n",
    "     'reg_lambda':(0,1.4),'colsample_bytree':(0.6,0.8),'max_bin':(128,512),'num_leaves':(2,32),'min_data_in_leaf':(20,200)}\n",
    "]\n",
    "\n",
    "y_traindata = np.log10(y_traindata) #GRACIAS A ESTA TRANSFORMACION CONSEGUIMOS QUE LA VARIABLE OBJETIVO SIGA UNA DISTRIBUCION NORMAL\n",
    "\n",
    "#separamos nuestro conjunto de train en train y validacion\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_traindata, y_traindata, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPARACION DE MODELOS CON O SIN ESTIMACION DE PARAMETROS\n",
    "#SE RECOMIENDA NO EJECUTAR ESTE CODIGO, PUES COMPARA MUCHOS MODELOS SOBRE UN DATASET MUY GRANDE\n",
    "#POR LO QUE TARDARA VARIAS HORAS\n",
    "compare_models(models_table, X_train, y_train, param_grid_list, verbose=1, cv=4)\n",
    "\n",
    "#Alternativamente podemos Comparar modelos cada uno con su combinacion de parametros por defecto (mas rapido)\n",
    "#compare_models(models_table, X_traindata, y_traindata, verbose=1, cv=4)#, metric=scorer)\n",
    "models_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOS QUEDAMOS CON EL MEJOR MODELO CON SU MEJOR COMBINACION DE PARAMETROS\n",
    "lightg=lgb.LGBMRegressor(objective='huber',n_estimators=804,learning_rate=0.1,subsample=1,max_depth=15,reg_alpha=1.4,\n",
    "     reg_lambda=0,colsample_bytree=0.8,max_bin=357,num_leaves=32,min_data_in_leaf=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4030.2613299009704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OBTENEMOS EL ERROR DE NUETRO MODELO SOBRE EL CONJUNTO DE VALIDACION\n",
    "log_scoring(y_val,fit_predict(lightg,X_train,y_train,X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The description of the submision:\n",
      "               PA_Est\n",
      "count  156315.000000\n",
      "mean    15262.960413\n",
      "std     11254.956463\n",
      "min      4477.449743\n",
      "25%      9504.925282\n",
      "50%     12722.722337\n",
      "75%     18008.632730\n",
      "max    633027.644677\n"
     ]
    }
   ],
   "source": [
    "#GENERAMOS LOS RESULTADOS\n",
    "submision=pd.DataFrame()\n",
    "submision['ID_Customer']=test_ids\n",
    "submision['PA_Est']=np.power(10,fit_predict(lightg,X_traindata,y_traindata,testdata))\n",
    "print('The description of the submision:\\n',submision.describe())\n",
    "submision.to_csv('Test_Mission.txt',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
