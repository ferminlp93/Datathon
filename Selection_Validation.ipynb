{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from Utilidades import *\n",
    "from Utilidades_selection_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder='Total'\n",
    "\n",
    "traindata=pd.read_csv(folder+'/traindata.csv')#reading the data\n",
    "testdata=pd.read_csv(folder+'/TEST.csv')#reading the data\n",
    "\n",
    "traindata=traindata.drop('ID_Customer',axis=1)\n",
    "test_ids=testdata['ID_Customer'] #Nos lo guardamos para submision\n",
    "testdata=testdata.drop('ID_Customer',axis=1)\n",
    "\n",
    "print('Number of rows and columns of the training set: ',traindata.shape)\n",
    "print('Number of rows and columns of the test set: ',testdata.shape)\n",
    "\n",
    "X_traindata=traindata.drop('Poder_Adquisitivo',axis=1)\n",
    "y_traindata=traindata['Poder_Adquisitivo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models=[\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    RandomForestRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    GradientBoostingRegressor(loss='huber'),\n",
    "    xgb.XGBRegressor(),\n",
    "    lgb.LGBMRegressor(objective='huber')\n",
    "]\n",
    "\n",
    "\n",
    "models_table=get_models_table(models)\n",
    "\n",
    "    \n",
    "param_grid_list=[\n",
    "    #LINEAR MODELS\n",
    "    {'alpha':(0.05,100)},\n",
    "    {'alpha':(0.0001,1.0)},\n",
    "    {'l1_ratio':(0.1,1),'alpha':(0.001,1)},\n",
    "    \n",
    "    #ENSEMBLE MODELS\n",
    "    {'n_estimators': (10, 300),'min_samples_split': (2, 25),'max_features': (0.1, 0.999),'max_depth': (4,12)},\n",
    "    {'n_estimators': (10, 300),'min_samples_split': (2, 25),'max_features': (0.1, 0.999),'max_depth': (4,12)},\n",
    "    \n",
    "    {'n_estimators':(100,3000),'learning_rate':(0.05,0.5),'subsample':(0.5,1),'max_depth':(5,15),\n",
    "     'min_samples_leaf':(5, 20),'min_samples_split':(2, 12),'alpha':(0,1.5)},\n",
    "    \n",
    "    {'n_estimators':(100,3000),'learning_rate':(0.05,0.5),'subsample':(0.5,1),'max_depth':(5,15),'reg_alpha':(0,1.4),\n",
    "     'reg_lambda':(0,1.4),'min_child_weight':(1,10),'colsample_bytree':(0.1,1),'gamma':(0,1.4)},\n",
    "    \n",
    "    {'n_estimators':(100,3000),'learning_rate':(0.005,0.1),'subsample':(0.5,1),'max_depth':(5,15),'reg_alpha':(0,1.4),\n",
    "     'reg_lambda':(0,1.4),'colsample_bytree':(0.6,0.8),'max_bin':(128,512),'num_leaves':(2,32),'min_data_in_leaf':(20,200)}\n",
    "]\n",
    "\n",
    "y_traindata = np.log10(y_traindata) #GRACIAS A ESTA TRANSFORMACION CONSEGUIMOS QUE LA VARIABLE OBJETIVO SIGA UNA DISTRIBUCION NORMAL\n",
    "\n",
    "#separamos nuestro conjunto de train en train y validacion\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_traindata, y_traindata, test_size=0.33)\n",
    "\n",
    "X_train=RobustScaler().fit_transform(X_train)\n",
    "X_val=RobustScaler().fit_transform(X_val)\n",
    "testdata=RobustScaler().fit_transform(testdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparamos modelos (cada uno con su mejor combinacion de parametros)\n",
    "compare_models(models_table, X_train, y_train, param_grid_list, verbose=1, cv=4)\n",
    "\n",
    "#Alternativamente podemos Comparar modelos cada uno con su combinacion de parametros por defecto (mas rapido)\n",
    "#compare_models(models_table, X_traindata, y_traindata, verbose=1, cv=4)#, metric=scorer)\n",
    "models_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecuta todo hasta aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Escogemos un modelo y sus parametros en base a los resultados obtenidos arriba\n",
    "#Validamos el modelo obteniendo el error para el conjunto de test\n",
    "key=models_table['error'].argmin()\n",
    "\n",
    "best_model=models_table.loc[key,'model'].set_params(**models_table.loc[key,'params'])\n",
    "print('Validation mean absolute error: ',mean_absolute_error(y_val,fit_predict(best_model,X_train,y_train,X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_traindata, y_traindata)\n",
    "\n",
    "submision=pd.DataFrame()\n",
    "submision['ID_Customer']=test_ids\n",
    "submision['PA_Est']=fit_predict(best_model,X_traindata,y_traindata,testdata)\n",
    "print('The description of the submision:\\n',submision.describe())\n",
    "submision.to_csv('Test_Mission.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred6=fit_predict(Stacking_model([Ridge(),Ridge()],Ridge()),X_train,y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred6=transformacion_exponencial(y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val,y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cv(Stacking_model([Ridge(),Ridge()],Ridge()),X_traindata,y_traindata,verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=fit_predict(GradientBoostingRegressor(n_estimators=3000,loss='huber'),X_train,y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2=fit_predict(xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1),X_train,y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred3=fit_predict(lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11),X_train,y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_val,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mae_cv(xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1),X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cv(Ridge(),X_traindata,y_traindata,cv=4,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
