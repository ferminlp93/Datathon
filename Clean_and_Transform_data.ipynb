{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fermin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_datasets():\n",
    "        #CARGAMOS LOS DATOS\n",
    "\n",
    "    traindata=pd.read_csv('Dataset_Salesforce_Predictive_Modelling_TRAIN.txt')#reading the data\n",
    "    testdata=pd.read_csv('Dataset_Salesforce_Predictive_Modelling_TEST.txt')\n",
    "    #print('Number of rows and columns of the training set: ',traindata.shape)\n",
    "    #print('Number of rows and columns of the test set: ',testdata.shape)\n",
    "    #VARIABLES DE CADA TIPO\n",
    "    list_columns_test=list(testdata.columns.values)\n",
    "    #Ver el nombre de las columnas para saber cuales sumar (buscar la mayor correlación)\n",
    "    list_columns=list(traindata.columns.values)\n",
    "    Names_Imp_cons=list_columns[0:17]\n",
    "    #Importe de consumos habituales del cliente en base a sus operaciones con tarjetas y domiciliaciones más comunes\n",
    "    traindata['Imp_cons_total'] = traindata[Names_Imp_cons].sum(axis=1)\n",
    "    #Importe de los saldos de los distintos productos financieros.\n",
    "    traindata['Imp_cons_total_2']=traindata['Imp_cons_total']**2\n",
    "    traindata['Imp_cons_total_3']=traindata['Imp_cons_total']**3\n",
    "    Names_Imp_Sal=list_columns[17:38]\n",
    "    traindata['Imp_sal_total'] = traindata[Names_Imp_Sal].sum(axis=1)\n",
    "    #Tenencia de los distintos productos financieros. Son indices entre 0 y 2 por lo que el sumatorio también valdra\n",
    "    #ya que cuanta más puntuación saque el sumatorio más productos compra\n",
    "    traindata['Imp_sal_total_2']=traindata['Imp_sal_total']**2\n",
    "    traindata['Imp_sal_total_3']=traindata['Imp_sal_total']**3\n",
    "    Names_Ind_Prod=list_columns[38:62]\n",
    "    traindata['Ind_prod_total'] = traindata[Names_Ind_Prod].sum(axis=1)\n",
    "    #Número de operaciones a través de los distintos productos financieros.\n",
    "    traindata['Ind_prod_total_2'] = traindata['Ind_prod_total']**2\n",
    "    traindata['Ind_prod_total_3'] = traindata['Ind_prod_total']**3\n",
    "    Names_Num_Oper=list_columns[62:82]\n",
    "    traindata['Num_Oper_total'] = traindata[Names_Num_Oper].sum(axis=1)\n",
    "\n",
    "    traindata['Num_Oper_total_2'] = traindata['Num_Oper_total']**2\n",
    "    traindata['Num_Oper_total_3'] = traindata['Num_Oper_total']**3\n",
    "    #datasetfinal\n",
    "    traindata['Relacion']=((traindata.Imp_sal_total+traindata.Ind_prod_total)*traindata.Num_Oper_total)-traindata.Imp_cons_total\n",
    "    #df = data[['Relacion','Imp_cons_total', 'Imp_sal_total', 'Ind_prod_total','Num_Oper_total','Socio_Demo_01','Socio_Demo_02','Socio_Demo_03','Socio_Demo_04','Socio_Demo_05','Poder_Adquisitivo']].copy()\n",
    "\n",
    "    traindata['Relacion_2'] = traindata['Relacion']**2\n",
    "    traindata['Relacion_3'] = traindata['Relacion']**3\n",
    "    #hacemos lo mismo con lo de test (la lista que contiene nombres nos sirve la misma)\n",
    "\n",
    "    testdata['Imp_cons_total'] = testdata[Names_Imp_cons].sum(axis=1)\n",
    "    testdata['Imp_cons_total_2'] = testdata['Imp_cons_total']**2\n",
    "    testdata['Imp_cons_total_3'] = testdata['Imp_cons_total']**3\n",
    "    testdata['Imp_sal_total'] = testdata[Names_Imp_Sal].sum(axis=1)\n",
    "    testdata['Imp_sal_total_2'] = testdata['Imp_sal_total']**2\n",
    "    testdata['Imp_sal_total_3'] = testdata['Imp_sal_total']**3\n",
    "    testdata['Ind_prod_total'] = testdata[Names_Ind_Prod].sum(axis=1)\n",
    "    testdata['Ind_prod_total_2'] = testdata['Ind_prod_total']**2\n",
    "    testdata['Ind_prod_total_3'] = testdata['Ind_prod_total']**3\n",
    "    testdata['Num_Oper_total'] = testdata[Names_Num_Oper].sum(axis=1)\n",
    "    testdata['Num_Oper_total_2'] = testdata['Num_Oper_total']**2\n",
    "    testdata['Num_Oper_total_3'] = testdata['Num_Oper_total']**3\n",
    "    testdata['Relacion']=((testdata.Imp_sal_total+testdata.Ind_prod_total)*testdata.Num_Oper_total)-testdata.Imp_cons_total\n",
    "    testdata['Relacion_2']= testdata['Relacion']**2\n",
    "    testdata['Relacion_3']= testdata['Relacion']**3\n",
    "    traindata.dtypes.value_counts()\n",
    "\n",
    "    numeric_cols=traindata.select_dtypes(include=[np.number]).columns#select only numerical\n",
    "    nominal_cols=traindata.select_dtypes(exclude=[np.number]).columns#select only non numerical\n",
    "    #EL ID DEL CLIENTE NO NOS SIRVE PARA NADA\n",
    "\n",
    "    #traindata['Poder_Adquisitivo_Ranges']=pd.qcut(traindata['Poder_Adquisitivo'],4,labels=[0,1,2,3])\n",
    "    traindata=traindata.drop('ID_Customer',axis=1) #remove the column from train\n",
    "    test_ids = testdata['ID_Customer'] #save id column from test\n",
    "    testdata=testdata.drop('ID_Customer',axis=1) #remove the column from test\n",
    "    nominal_cols=nominal_cols[nominal_cols!='Id'] #remove the column name from this list as well\n",
    "\n",
    "    #CONCATENAMOS AMBOS CONJUNTOS PARA APLICAR TRANSFORMACIONES\n",
    "    #Sacamos columna para el clasificador\n",
    "\n",
    "\n",
    "    data=pd.concat([traindata,testdata],axis=0,ignore_index=True) #concatenate training and test set for future transformat\n",
    "\n",
    "    stdSc = StandardScaler()\n",
    "\n",
    "    numeric_cols=numeric_cols[numeric_cols!='Poder_Adquisitivo'] #We don't want to scale SalePrice\n",
    "\n",
    "    data.loc[:, numeric_cols] = stdSc.fit_transform(data.loc[:, numeric_cols])\n",
    "\n",
    "    #SEPARAMOS DE NUEVO LOS CONJUNTOS\n",
    "\n",
    "    traindata=data.iloc[:traindata.shape[0],:] \n",
    "    testdata=data.iloc[traindata.shape[0]:,:]\n",
    "    testdata=testdata.drop('Poder_Adquisitivo',axis=1) #We drop the unknown variable in the test. It was just filled with NAs\n",
    "\n",
    "    X_traindata=traindata.drop('Poder_Adquisitivo',axis=1)\n",
    "    y_traindata=traindata['Poder_Adquisitivo']\n",
    "    X_traindata_Sin_totales = X_traindata.drop(['Imp_cons_total','Imp_sal_total','Ind_prod_total','Num_Oper_total','Relacion', \\\n",
    "                                         'Imp_cons_total_2','Imp_sal_total_2','Ind_prod_total_2','Num_Oper_total_2','Relacion_2', \\\n",
    "                                         'Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "\n",
    "    Test_data_Sin_totales = testdata.drop(['Imp_cons_total','Imp_sal_total','Ind_prod_total','Num_Oper_total','Relacion', \\\n",
    "                                         'Imp_cons_total_2','Imp_sal_total_2','Ind_prod_total_2','Num_Oper_total_2','Relacion_2', \\\n",
    "                                         'Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "\n",
    "    X_traindata_Con_totales = X_traindata.drop(['Imp_cons_total_2','Imp_sal_total_2','Ind_prod_total_2','Num_Oper_total_2','Relacion_2', \\\n",
    "                                         'Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "\n",
    "    Test_data_Con_totales = testdata.drop(['Imp_cons_total_2','Imp_sal_total_2','Ind_prod_total_2','Num_Oper_total_2','Relacion_2', \\\n",
    "                                         'Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "\n",
    "    X_traindata_Con_totales_y_cuadrados = X_traindata.drop(['Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "\n",
    "    Test_data_Con_totales_y_cuadrados = testdata.drop(['Imp_cons_total_3','Imp_sal_total_3','Ind_prod_total_3','Num_Oper_total_3','Relacion_3'],axis=1)\n",
    "    if not os.path.exists('Total'):\n",
    "        os.makedirs('Total')\n",
    "    if not os.path.exists('Sin_Totales'):\n",
    "        os.makedirs('Sin_Totales')\n",
    "    if not os.path.exists('Con_Totales'):\n",
    "        os.makedirs('Con_Totales')\n",
    "    if not os.path.exists('Con_Totales_y_Cuadrados'):\n",
    "        os.makedirs('Con_Totales_y_Cuadrados')\n",
    "\n",
    "    X_traindata.to_csv('./Total/X_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    y_traindata.to_csv('./Total/y_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    testdata.to_csv('./Total/TEST.csv', sep=',', encoding='utf-8',index=False)\n",
    "\n",
    "    X_traindata_Sin_totales.to_csv('./Sin_Totales/X_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    y_traindata.to_csv('./Sin_Totales/y_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    Test_data_Sin_totales.to_csv('./Sin_Totales/TEST.csv', sep=',', encoding='utf-8',index=False)\n",
    "\n",
    "    X_traindata_Con_totales.to_csv('./Con_Totales/X_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    y_traindata.to_csv('./Con_Totales/y_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    Test_data_Con_totales.to_csv('./Con_Totales/TEST.csv', sep=',', encoding='utf-8',index=False)\n",
    "\n",
    "    X_traindata_Con_totales_y_cuadrados.to_csv('./Con_Totales_y_Cuadrados/X_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    y_traindata.to_csv('./Con_Totales_y_Cuadrados/y_traindata.csv', sep=',', encoding='utf-8',index=False)\n",
    "    Test_data_Con_totales_y_cuadrados.to_csv('./Con_Totales_y_Cuadrados/TEST.csv', sep=',', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
